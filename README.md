# Look at What I’m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos

![alt text](motivational.png)

This repository contains a PyTorch implementation of the paper [Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News](https://arxiv.org/abs/2009.07698) accepted at EMNLP 2020. If you find this implementation or the paper helpful, please consider citing:

    @InProceedings{tanDIDAN2020,
         author={Reuben Tan and Bryan A. Plummer and Kate Saenko},
         title={Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News},
         booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
         year={2020} }

This repository contains a PyTorch implementation of the paper [Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News](https://arxiv.org/abs/2009.07698) accepted at EMNLP 2020. If you find this implementation or the paper helpful, please consider citing:

@inproceedings{tanCOMMA2021,
         author = {Reuben Tan and Bryan A. Plummer and Kate Saenko and Hailin Jin and Bryan Russell},
         title = {Look at What I’m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos},
         booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
         year = {2021} }
